{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEMA DE NEGÓCIO: PREVER O CUSTO ANUAL COM CONVÊNIO MÉDICO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALAÇÃO E CARREGAMENTO DOS PACOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-talk')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "df = pd.read_csv('Medicalpremium.csv', sep = ',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE EXPLORATÓRIA, LIMPEZA E TRANFORMAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o tipo dos dados\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as dimensões\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando as colunas\n",
    "colunas = ['Idade', 'Diabetes', 'Problema_Pressao', 'Transplantes', 'Doencas_Cronicas', 'Altura', 'Peso', 'Alergias', 'Historico_Cancer_Familia','Qtd_Cirurgias','Preco_Convenio']\n",
    "df.columns = colunas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo\n",
    "print(\"Linhas: \", df.shape[0])\n",
    "print(\"Colunas: \", df.shape[1])\n",
    "print(\"\\nVariáveis: \\n\", df.columns.tolist())\n",
    "print(\"\\nValores Ausentes: \\n\" , df.isnull().sum())\n",
    "print(\"\\nValores Únicos: \\n\", df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas numéricas (quantitativas)\n",
    "colunas_numericas = ['Idade', 'Altura', 'Peso', 'Preco_Convenio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas categóricas\n",
    "colunas_categoricas = ['Diabetes', 'Problema_Pressao', 'Transplantes', 'Doencas_Cronicas', 'Alergias', 'Historico_Cancer_Familia', 'Qtd_Cirurgias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se o total de variáveis está coberto nos objetos anteriores\n",
    "len(colunas_numericas) + len(colunas_categoricas) == 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes com os tipos diferentes de variáveis\n",
    "df_num = df[colunas_numericas]\n",
    "df_cat = df[colunas_categoricas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico das variáveis numéricas\n",
    "sumario_num = pd.DataFrame(index = df_num.columns)\n",
    "sumario_num['Tipo de Dado'] = df_num.dtypes.values\n",
    "sumario_num['Registros Não Nulos'] = df_num.count().values\n",
    "sumario_num['Registros Não Zero'] = df_num.astype(bool).sum(axis = 0)\n",
    "sumario_num['% Populado'] = round(sumario_num['Registros Não Nulos'] / df_num.shape[0]*100,2)\n",
    "sumario_num['Valores Únicos'] = df_num.nunique().values\n",
    "sumario_num['Mean'] = round(df_num.mean(),2)\n",
    "sumario_num['Std'] = round(df_num.std(),2)\n",
    "sumario_num['Min'] = round(df_num.min(),2)\n",
    "sumario_num['Max'] = round(df_num.max(),2)\n",
    "sumario_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando variáveis numéricas em categóricas\n",
    "# df_cat = df_cat.astype('category')\n",
    "\n",
    "# Sumário estatístico das variáveis categóricas\n",
    "sumario_cat = pd.DataFrame(index = df_cat.columns)\n",
    "sumario_cat['Tipo de Dado'] = df_cat.dtypes.values\n",
    "sumario_cat['Registros Não Nulos'] = df_cat.count().values\n",
    "sumario_cat['% Populado'] = round(sumario_cat['Registros Não Nulos'] / df_cat.shape[0]*100,2)\n",
    "sumario_cat['# Valores Únicos'] = df_cat.nunique().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona mais uma coluna com valores mais comuns\n",
    "temp = []\n",
    "for coluna in colunas_categoricas:\n",
    "    temp.append(df_cat[coluna].value_counts().idxmax())\n",
    "sumario_cat['Valores Mais Comuns'] = temp\n",
    "sumario_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZAÇÃO DAS VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 1 - Idade\n",
    "df['Idade'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (20, 10))\n",
    "fig1 = sns.countplot(x = 'Idade', data = df, color='lightblue')\n",
    "plt.title(\"Número de Individuos em Diferentes Idades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig2 = sns.boxplot(x = 'Idade',  data = df, orient = 'v', color='lightblue')\n",
    "plt.title(\"Boxplot Idade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (20, 10))\n",
    "fig3 = sns.histplot(df, x = 'Idade', color= 'blue', kde = True, bins = 20)\n",
    "plt.title(\"Histograma Idade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 2 - Diabetes\n",
    "diabetes = df['Diabetes'].value_counts().rename_axis('Diabetes').reset_index(name = 'Total')\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig4 = sns.countplot(x = 'Diabetes', data = df)\n",
    "plt.title(\"Diabetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 3 - Pressão Alta\n",
    "pressão_alta = df['Problema_Pressao'].value_counts().rename_axis('Pressão').reset_index(name = 'Total')\n",
    "pressão_alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig5 = sns.countplot(x = 'Problema_Pressao', data = df)\n",
    "plt.title(\"Problema de Pressão Alta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 4 - Transplantes\n",
    "transplantes = df['Transplantes'].value_counts().rename_axis('Transplantes').reset_index(name = 'Total')\n",
    "transplantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig6 = sns.countplot(x = 'Transplantes', data = df)\n",
    "plt.title(\"Transplantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 5 - Doenças Crônicas\n",
    "doencas_cronicas= df['Doencas_Cronicas'].value_counts().rename_axis('Doencas_Cronicas').reset_index(name = 'Total')\n",
    "doencas_cronicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig7 = sns.countplot(x = 'Doencas_Cronicas', data = df)\n",
    "plt.title(\"Doenças Crônicas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 6 - Estatura\n",
    "df['Altura'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (20, 10))\n",
    "fig8 = sns.countplot(x = 'Altura', data = df, color='lightblue')\n",
    "plt.title(\"Estatura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig9 = sns.boxplot(x = 'Altura', data = df, color='lightblue', orient = 'v')\n",
    "plt.title(\"Boxplot Estatura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig10 = sns.histplot(df, x = 'Altura', color= 'blue', kde = True)\n",
    "plt.title(\"Histograma Estatura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 7 - Peso\n",
    "df['Peso'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (20, 10))\n",
    "fig11 = sns.countplot(x = 'Peso', data = df, color='lightblue')\n",
    "plt.title(\"Peso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig12 = sns.boxplot(x = 'Peso', data = df, color='lightblue', orient = 'v')\n",
    "plt.title(\"Boxplot Peso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig13 = sns.histplot(df, x = 'Peso', color= 'blue', kde = True)\n",
    "plt.title(\"Histograma Peso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 8 - Alergias\n",
    "alergias= df['Alergias'].value_counts().rename_axis('Alergias').reset_index(name = 'Total')\n",
    "alergias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig14 = sns.countplot(x = 'Alergias', data = df)\n",
    "plt.title(\"Alergias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 9 - Histórico de Cancer na Família\n",
    "cancer= df['Historico_Cancer_Familia'].value_counts().rename_axis('Cancer_Familia').reset_index(name = 'Total')\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig15 = sns.countplot(x = 'Historico_Cancer_Familia', data = df)\n",
    "plt.title(\"Histórico de Cancer na Família\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 10 - Quantidade de Cirurgias\n",
    "cirurgias= df['Qtd_Cirurgias'].value_counts().rename_axis('Cirurgias').reset_index(name = 'Total')\n",
    "cirurgias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid')\n",
    "plt.figure(figsize = (10, 6))\n",
    "fig16 = sns.countplot(x = 'Qtd_Cirurgias', data = df)\n",
    "plt.title(\"Quantidad de Cirurgias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 11 (Target) - Preço do Convêvio\n",
    "df['Preco_Convenio'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (20, 10))\n",
    "fig17 = sns.countplot(x = 'Preco_Convenio', data = df, color='lightblue')\n",
    "plt.title(\"Preço do Convênio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig18 = sns.boxplot(x = 'Preco_Convenio', data = df, color='lightblue', orient = \"v\")\n",
    "plt.title(\"Boxplot Preço do Convênio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (8, 8))\n",
    "fig19 = sns.histplot(df, x = 'Preco_Convenio', color= 'blue', kde = True, bins = 10)\n",
    "plt.title(\"Histograma Preço do Convênio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação \n",
    "corr = df.corr().stack().reset_index(name=\"correlation\")\n",
    "\n",
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (10, 10))\n",
    "fig20 = sns.relplot(data=corr, x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n",
    "                    palette=\"vlag\", hue_norm=(-1, 1), edgecolor=\".8\", height=10, sizes=(150, 300))\n",
    "plt.title(\"Matriz de Correlação\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação com as variáveis quantitativas\n",
    "corr2 = df_num.corr()\n",
    "corr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARAÇÃO DOS DADOS (PRÉ-PROCESSAMENTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO - Transformando os dados para a mesma escala (entre 0 e 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados = df.values\n",
    "x = dados[:,0:10]\n",
    "y = dados[:,10]\n",
    "\n",
    "# Gerando a nova escala (normalizando os dados)\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dados_normalizados = scaler.fit_transform(x)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Normalizados: \\n\\n\", dados_normalizados[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADRONIZAÇÃO - Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "x2 = dados[:,0:10]\n",
    "y2 = dados[:,10]\n",
    "\n",
    "# Gerando o novo padrão\n",
    "scaler = StandardScaler().fit(x2)\n",
    "dados_padronizados = scaler.transform(x2)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Padronizados: \\n\\n\", dados_padronizados[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO E PADRONIZAÇÃO\n",
    "\n",
    "# Gerando o novo padrão\n",
    "scaler = StandardScaler().fit(dados_normalizados)\n",
    "dados_norm_padr = scaler.transform(dados_normalizados)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Padronizados: \\n\\n\", dados_norm_padr[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAGEM PREDITIVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSÃO LINEAR MULTIPLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regressão Linear 1\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Separando os dados em conjuntos de treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(dados_normalizados, y, test_size = 0.30)\n",
    "print(x_treino.shape, y_treino.shape, x_teste.shape, y_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de REGRESSÃO LINEAR - Utilização dos dados Normalizados\n",
    "modelo_v1 = linear_model.LinearRegression(normalize = True)\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v1.fit(x_treino, y_treino)\n",
    "modelo_v1.score(x_treino, y_treino)\n",
    "\n",
    "# Coletando os coeficientes\n",
    "print('Coefficient: \\n', modelo_v1.coef_)\n",
    "print('Intercept: \\n', modelo_v1.intercept_)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v1 = modelo_v1.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a métrica R2 do nosso modelo_v1\n",
    "r2_score(y_teste, modelo_v1.fit(x_treino, y_treino).predict(x_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v1 nos dados de teste\n",
    "v1_acuracia = modelo_v1.score(x_teste, y_teste)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v1_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo utilizando o CROSS VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "num_folds = 30\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = modelo_v1\n",
    "resultado = cross_val_score(modelo, x, y, cv = kfold)\n",
    "\n",
    "# Usamos a média e o desvio padrão\n",
    "print(\"Acurácia Final: %.2f%%\" % (resultado.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regressão Linear 2\n",
    "\n",
    "# Separando os dados em conjuntos de treino e teste\n",
    "x_treino2, x_teste2, y_treino2, y_teste2 = train_test_split(dados_padronizados, y, test_size = 0.30)\n",
    "print(x_treino2.shape, y_treino2.shape, x_teste2.shape, y_teste2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de REGRESSÃO LINEAR - Utilização dos dados Padronizados\n",
    "modelo_v2 = linear_model.LinearRegression(normalize = True)\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v2.fit(x_treino2, y_treino2)\n",
    "modelo_v2.score(x_treino2, y_treino2)\n",
    "\n",
    "# Coletando os coeficientes\n",
    "print('Coefficient: \\n', modelo_v2.coef_)\n",
    "print('Intercept: \\n', modelo_v2.intercept_)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v2 = modelo_v2.predict(x_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a métrica R2 do nosso modelo\n",
    "r2_score(y_teste2, modelo_v2.fit(x_treino2, y_treino2).predict(x_teste2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v2 nos dados de teste\n",
    "v2_acuracia = modelo_v2.score(x_teste2, y_teste2)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v2_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSÃO DE RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de REGRESSÃO DE RIDGE - Utilização dos dados Normalizados\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "modelo_v3 = Ridge()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v3.fit(x_treino, y_treino)\n",
    "modelo_v3.score(x_treino, y_treino)\n",
    "\n",
    "# Coletando os coeficientes\n",
    "print('Coefficient: \\n', modelo_v3.coef_)\n",
    "print('Intercept: \\n', modelo_v3.intercept_)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v3 = modelo_v3.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v3 nos dados de teste\n",
    "v3_acuracia = modelo_v3.score(x_teste, y_teste)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v3_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo utilizando o CROSS VALIDATION\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "num_folds = 20\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = modelo_v3\n",
    "resultado = cross_val_score(modelo, x, y, cv = kfold)\n",
    "\n",
    "# Usamos a média e o desvio padrão\n",
    "print(\"Acurácia Final: %.2f%%\" % (resultado.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de REGRESSÃO DE RIDGE - Utilização dos dados Padronizados\n",
    "modelo_v4 = Ridge()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v4.fit(x_treino2, y_treino2)\n",
    "modelo_v4.score(x_treino2, y_treino2)\n",
    "\n",
    "# Coletando os coeficientes\n",
    "print('Coefficient: \\n', modelo_v4.coef_)\n",
    "print('Intercept: \\n', modelo_v4.intercept_)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v4 = modelo_v4.predict(x_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v4 nos dados de teste\n",
    "v4_acuracia = modelo_v4.score(x_teste2, y_teste2)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v4_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSÃO DE LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de REGRESSÃO DE LASSO - Utilização dos dados Normalizados\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "modelo_v5 = Lasso()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v5.fit(x_treino, y_treino)\n",
    "modelo_v5.score(x_treino, y_treino)\n",
    "\n",
    "# Coletando os coeficientes\n",
    "print('Coefficient: \\n', modelo_v5.coef_)\n",
    "print('Intercept: \\n', modelo_v5.intercept_)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v5 = modelo_v5.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v5 nos dados de teste\n",
    "v5_acuracia = modelo_v5.score(x_teste, y_teste)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v5_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo utilizando o CROSS VALIDATION\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "num_folds = 10\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = modelo_v5\n",
    "resultado = cross_val_score(modelo, x, y, cv = kfold)\n",
    "\n",
    "# Usamos a média e o desvio padrão\n",
    "print(\"Acurácia Final: %.2f%%\" % (resultado.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de REGRESSÃO DE RIDGE - Utilização dos dados Padronizados\n",
    "modelo_v6 = Lasso()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v6.fit(x_treino2, y_treino2)\n",
    "modelo_v6.score(x_treino2, y_treino2)\n",
    "\n",
    "# Coletando os coeficientes\n",
    "print('Coefficient: \\n', modelo_v6.coef_)\n",
    "print('Intercept: \\n', modelo_v6.intercept_)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v6 = modelo_v6.predict(x_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v6 nos dados de teste\n",
    "v6_acuracia = modelo_v6.score(x_teste2, y_teste2)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v6_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Normalizados\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo_v7 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v7.fit(x_treino, y_treino)\n",
    "modelo_v7.score(x_treino, y_treino)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v7 = modelo_v7.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v5 nos dados de teste\n",
    "v7_acuracia = modelo_v7.score(x_teste, y_teste)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v7_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Padronizados\n",
    "modelo_v8 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v8.fit(x_treino2, y_treino2)\n",
    "modelo_v8.score(x_treino2, y_treino2)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v8 = modelo_v8.predict(x_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v6 nos dados de teste\n",
    "v8_acuracia = modelo_v8.score(x_teste2, y_teste2)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v8_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Random Forest 3\n",
    "\n",
    "# Separando os dados em conjuntos de treino e teste\n",
    "x_treino3, x_teste3, y_treino3, y_teste3 = train_test_split(dados_norm_padr, y, test_size = 0.30)\n",
    "print(x_treino3.shape, y_treino3.shape, x_teste3.shape, y_teste3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Normalizados e Padronizados\n",
    "modelo_v9 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v9.fit(x_treino3, y_treino3)\n",
    "modelo_v9.score(x_treino3, y_treino3)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v9 = modelo_v9.predict(x_teste3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v5 nos dados de teste\n",
    "v9_acuracia = modelo_v9.score(x_teste3, y_teste3)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v9_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARAÇÃO ENTRE OS MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = ['Regressão Linear', 'Regressão Ridge', 'Regressão Lasso', 'Random Forest']\n",
    "lista2 = [v2_acuracia * 100.0, v3_acuracia * 100.0, v5_acuracia * 100.0, v9_acuracia * 100.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparação_resultados = pd.DataFrame(list(zip(lista, lista2)), columns = ['Algoritmo','Acuracia'])\n",
    "comparação_resultados.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos os algoritmos apresentaram maior acuracia com os dados normalizados em comparação com os dados padronizados.\n",
    "# O algortimo Random Forest apresentou maior acuracia (80,16%) entre todos os modelos, conforme demonstrado na tabela acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTIMIZAÇÃO DO MODELO SELECIONADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGENHARIA DE ATRIBUTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação da variável idade em faixa etária\n",
    "df2 = df.copy()\n",
    "\n",
    "for item in range(0,len(df2['Idade']),1):\n",
    "   \n",
    "    if int(df2['Idade'][item]) >= 18 and int(df2['Idade'][item]) <=30:\n",
    "        df2['Idade'][item]= 0\n",
    "    elif int(df2['Idade'][item]) >= 31 and int(df2['Idade'][item]) <=40:\n",
    "        df2['Idade'][item]= 1\n",
    "    elif int(df2['Idade'][item]) >= 41 and int(df2['Idade'][item]) <=50:\n",
    "        df2['Idade'][item]= 2\n",
    "    elif int(df2['Idade'][item]) >= 51 and int(df2['Idade'][item]) <=60:\n",
    "        df2['Idade'][item]= 3\n",
    "    elif int(df2['Idade'][item]) >= 61 and int(df2['Idade'][item]) <=70:\n",
    "        df2['Idade'][item]= 4\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO - Transformando os dados para a mesma escala (entre 0 e 1)\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados_rf = df2.values\n",
    "x4 = dados_rf[:,0:10]\n",
    "y = dados[:,10]\n",
    "\n",
    "# Gerando a nova escala (normalizando os dados)\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dados_norm_rf = scaler.fit_transform(x4)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Normalizados: \\n\\n\", dados_norm_rf[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADRONIZAÇÃO - Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "x5 = dados_rf[:,0:10]\n",
    "y5 = dados_rf[:,10]\n",
    "\n",
    "# Gerando o novo padrão\n",
    "scaler = StandardScaler().fit(x5)\n",
    "dados_padr_rf = scaler.transform(x5)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Padronizados: \\n\\n\", dados_padr_rf[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados em conjuntos de treino e teste\n",
    "x_treino5, x_teste5, y_treino5, y_teste5 = train_test_split(dados_norm_rf, y, test_size = 0.30)\n",
    "print(x_treino5.shape, y_treino5.shape, x_teste5.shape, y_teste5.shape)\n",
    "\n",
    "x_treino6, x_teste6, y_treino6, y_teste6 = train_test_split(dados_padr_rf, y, test_size = 0.30)\n",
    "print(x_treino6.shape, y_treino6.shape, x_teste6.shape, y_teste6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Normalizados\n",
    "\n",
    "modelo_v10 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v10.fit(x_treino5, y_treino5)\n",
    "modelo_v10.score(x_treino5, y_treino5)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v10 = modelo_v10.predict(x_teste5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v10 nos dados de teste\n",
    "v10_acuracia = modelo_v10.score(x_teste5, y_teste5)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v10_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Padronizados\n",
    "\n",
    "modelo_v11 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v11.fit(x_treino6, y_treino6)\n",
    "modelo_v11.score(x_treino6, y_treino6)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v11 = modelo_v11.predict(x_teste6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v11 nos dados de teste\n",
    "v11_acuracia = modelo_v11.score(x_teste6, y_teste6)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v11_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação as variáveis peso e altura em IMC\n",
    "df3 = df2.copy()\n",
    "df3['Altura_m'] = list(map(lambda num: num / 100, df3['Altura']))\n",
    "df3['IMC']= (df3['Peso'] / df3['Altura_m']**2).round(2)\n",
    "df3.drop(columns=[\"Altura\", \"Peso\", \"Altura_m\"],inplace=True)\n",
    "df3 = df3[['Idade','Diabetes', 'Problema_Pressao', 'Transplantes', 'Doencas_Cronicas', 'Alergias', 'Historico_Cancer_Familia', 'Qtd_Cirurgias', 'IMC', 'Preco_Convenio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO - Transformando os dados para a mesma escala (entre 0 e 1)\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados_rf2 = df3.values\n",
    "x6 = dados_rf2[:,0:9]\n",
    "y6 = dados_rf2[:,9]\n",
    "\n",
    "# Gerando a nova escala (normalizando os dados)\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dados_norm_rf2 = scaler.fit_transform(x6)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Normalizados: \\n\\n\", dados_norm_rf2[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADRONIZAÇÃO - Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "x7 = dados_rf2[:,0:9]\n",
    "y7 = dados_rf2[:,9]\n",
    "\n",
    "# Gerando o novo padrão\n",
    "scaler = StandardScaler().fit(x7)\n",
    "dados_padr_rf2 = scaler.transform(x7)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df.values)\n",
    "print(\"\\nDados Padronizados: \\n\\n\", dados_padr_rf2[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados em conjuntos de treino e teste\n",
    "x_treino7, x_teste7, y_treino7, y_teste7 = train_test_split(dados_norm_rf2, y6, test_size = 0.30)\n",
    "print(x_treino7.shape, y_treino7.shape, x_teste7.shape, y_teste7.shape)\n",
    "\n",
    "x_treino8, x_teste8, y_treino8, y_teste8 = train_test_split(dados_padr_rf2, y7, test_size = 0.30)\n",
    "print(x_treino8.shape, y_treino8.shape, x_teste8.shape, y_teste8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Normalizados\n",
    "\n",
    "modelo_v12 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v12.fit(x_treino7, y_treino7)\n",
    "modelo_v12.score(x_treino7, y_treino7)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v12 = modelo_v12.predict(x_teste7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v11 nos dados de teste\n",
    "v12_acuracia = modelo_v12.score(x_teste7, y_teste7)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v12_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Padronizados\n",
    "\n",
    "modelo_v13 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v13.fit(x_treino8, y_treino8)\n",
    "modelo_v13.score(x_treino8, y_treino8)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v13 = modelo_v13.predict(x_teste8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v11 nos dados de teste\n",
    "v13_acuracia = modelo_v13.score(x_teste8, y_teste8)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v13_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizado a Engenharia de Atributos, pode-se concluir que o melhor modelo foi o v10 (82,83%) utilizando a transformação \n",
    "# das idades em faixa etária. O cálculo do IMC não contribuiu para uma melhor acuracia no modelo subsequentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTES DE HIPERPARÂMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM SEARCH PARAMETER TUNING\n",
    "# Este método gera amostras dos parâmetros dos algoritmos a partir de uma distribuição randômica uniforme para um número fixo\n",
    "# de iterações. Um modelo é construído e testado para cada combinação de parâmetros.\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "modelo_hp = RandomForestRegressor()\n",
    "x_treino_final = x_treino5\n",
    "y_treino_final = y_treino5\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "iteracoes = 50\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'n_estimators': [100, 150, 200, 250, 300], 'min_samples_leaf': [1, 2, 3], 'criterion': ['mse', 'mae'], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# Criando o grid\n",
    "rsearch = RandomizedSearchCV(estimator = modelo_hp, \n",
    "                             param_distributions = valores_grid, \n",
    "                             n_iter = iteracoes)\n",
    "rsearch.fit(x_treino_final, y_treino_final)\n",
    "\n",
    "# Print dos resultados\n",
    "print(\"Acurácia: %.2f\" % (rsearch.best_score_ * 100))\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREVISÃO COM O MODELO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produz a matriz com os novos dados de entrada para a previsão\n",
    "Idade = 49\n",
    "Diabetes = 1\n",
    "Problema_Pressao = 0\n",
    "Transplantes = 1\n",
    "Doencas_Cronicas = 1\n",
    "Altura = 175\n",
    "Peso = 81\n",
    "Alergias = 0\n",
    "Historico_Cancer_Familia = 1\n",
    "Qtd_Cirurgias = 3\n",
    "\n",
    "# Lista com os valores das variáveis\n",
    "dados_novo_cliente = [Idade, Diabetes, Problema_Pressao, Transplantes, Doencas_Cronicas, Altura, Peso, Alergias, Historico_Cancer_Familia, Qtd_Cirurgias]\n",
    "\n",
    "# Reshape\n",
    "novo_cliente = np.array(dados_novo_cliente).reshape(1, -1)\n",
    "\n",
    "# Previsão\n",
    "print(\"Preço previsto para o Convênio: %.2f%%\" % (modelo_v10.predict(novo_cliente)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # SALVANDO O MELHOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = 'PREVISAO_FINAL.sav'\n",
    "pickle.dump(modelo_v10, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o arquivo\n",
    "modelo_v10_final = pickle.load(open(arquivo, 'rb'))\n",
    "modelo_prod = modelo_v10_final.score(x_teste5, y_teste5)\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (modelo_prod * 100.0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
